{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lElF3o5PR6ys"
   },
   "source": [
    "# Pythonic Personal Wellness Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Imports and Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from getpass import getpass\n",
    "\n",
    "openai.api_key = getpass(\"OpenAI API Key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9OrFZRnER6yt"
   },
   "outputs": [],
   "source": [
    "# Enable nested async event loops in Jupyter notebooks\n",
    "# Jupyter runs its own event loop, which normally prevents asyncio.run() from working.\n",
    "# nest_asyncio patches asyncio to allow nested loops, enabling async code (like batch embeddings) to execute.\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjmC0KFtR6yt"
   },
   "source": [
    "> **üì¶ Local Library: `aimakerspace/`**\n",
    "> \n",
    "> The imports below come from the **local `aimakerspace/` package** included in this repository‚Äînot from PyPI. This custom library provides:\n",
    "> - `text_utils.py` ‚Üí `TextFileLoader`, `CharacterTextSplitter` for document loading and chunking\n",
    "> - `vectordatabase.py` ‚Üí `VectorDatabase` for in-memory vector storage and similarity search\n",
    "> - `openai_utils/` ‚Üí Wrappers for OpenAI embeddings, chat models, and prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z1dyrG4hR6yt"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOCAL LIBRARY IMPORTS: aimakerspace/\n",
    "# These classes are defined in the local ./aimakerspace/ directory, NOT from PyPI\n",
    "# =============================================================================\n",
    "from aimakerspace.text_utils import TextFileLoader, CharacterTextSplitter  # ./aimakerspace/text_utils.py\n",
    "from aimakerspace.vectordatabase import VectorDatabase  # ./aimakerspace/vectordatabase.py\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0jGnpQsR6yu"
   },
   "source": [
    "## Task 2: Documents\n",
    "\n",
    "> **üìÅ Local Data Directory: `data/`**\n",
    "> \n",
    "> Source documents are stored in the **local `data/` directory**. This repository includes:\n",
    "> - `data/HealthWellnessGuide.txt` ‚Äî Primary knowledge base for the wellness assistant\n",
    "> \n",
    "> The `TextFileLoader` class (from local `aimakerspace/text_utils.py`) handles reading these files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SFPWvRUR6yu"
   },
   "source": [
    "### Loading Source Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ia2sUEuGR6yu",
    "outputId": "84937ecc-c35f-4c4a-a4ab-9da72625954c"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOCAL DATA: Loading from ./data/ directory\n",
    "# TextFileLoader is from local aimakerspace/text_utils.py\n",
    "# =============================================================================\n",
    "text_loader = TextFileLoader(\"data/HealthWellnessGuide.txt\")  # Local data file\n",
    "documents = text_loader.load_documents()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bV-tj5WFR6yu",
    "outputId": "674eb315-1ff3-4597-bcf5-38ece0a812ac"
   },
   "outputs": [],
   "source": [
    "print(documents[0][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHlTvCzYR6yu"
   },
   "source": [
    "### Splitting Text Into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UMC4tsEmR6yv",
    "outputId": "08689c0b-57cd-4040-942a-8193e997f5cb"
   },
   "outputs": [],
   "source": [
    "# CharacterTextSplitter is from local aimakerspace/text_utils.py\n",
    "# Default: chunk_size=1000, chunk_overlap=200\n",
    "text_splitter = CharacterTextSplitter()\n",
    "split_documents = text_splitter.split_texts(documents)\n",
    "len(split_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vcYMwWJoR6yv",
    "outputId": "20d69876-feca-4826-b4be-32915276987a"
   },
   "outputs": [],
   "source": [
    "split_documents[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOU-RFP_R6yv"
   },
   "source": [
    "## Task 3: Embeddings and Vectors\n",
    "\n",
    "> **üì¶ Local Library: `aimakerspace/vectordatabase.py`**\n",
    "> \n",
    "> The `VectorDatabase` class (imported earlier from local `aimakerspace/`) provides:\n",
    "> - In-memory storage for text ‚Üí embedding vector mappings\n",
    "> - `abuild_from_list()` ‚Äî Async method to embed and store documents\n",
    "> - `search_by_text()` ‚Äî Cosine similarity search for semantic retrieval\n",
    "> \n",
    "> Internally uses `EmbeddingModel` from `aimakerspace/openai_utils/embedding.py` which calls OpenAI's `text-embedding-3-small` (1536 dimensions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O4KoLbVDR6yv"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOCAL LIBRARY: VectorDatabase from aimakerspace/vectordatabase.py\n",
    "# Uses EmbeddingModel from aimakerspace/openai_utils/embedding.py internally\n",
    "# =============================================================================\n",
    "vector_db = VectorDatabase()\n",
    "vector_db = asyncio.run(vector_db.abuild_from_list(split_documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-vWANZyR6yw"
   },
   "source": [
    "### Validate Vector DB Retrieval\n",
    "\n",
    "- currently uses semantic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76d96uavR6yw",
    "outputId": "bbfccc31-20a2-41c7-c14d-46554a43ed2d"
   },
   "outputs": [],
   "source": [
    "vector_db.search_by_text(\"What exercises help with lower back pain?\", k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TehsfIiKR6yw"
   },
   "source": [
    "## Task 4: Prompts\n",
    "\n",
    "> **üì¶ Local Library: `aimakerspace/openai_utils/`**\n",
    "> \n",
    "> The prompt and chat utilities below come from the **local `aimakerspace/openai_utils/` directory**:\n",
    "> - `prompts.py` ‚Üí `UserRolePrompt`, `SystemRolePrompt`, `AssistantRolePrompt` for message formatting\n",
    "> - `chatmodel.py` ‚Üí `ChatOpenAI` wrapper for OpenAI chat completions (uses `gpt-4.1-mini`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WIfpIot7R6yw"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOCAL LIBRARY IMPORTS: aimakerspace/openai_utils/\n",
    "# These classes are defined in the local ./aimakerspace/openai_utils/ directory\n",
    "# =============================================================================\n",
    "from aimakerspace.openai_utils.prompts import (  # ./aimakerspace/openai_utils/prompts.py\n",
    "    UserRolePrompt,\n",
    "    SystemRolePrompt,\n",
    "    AssistantRolePrompt,\n",
    ")\n",
    "\n",
    "from aimakerspace.openai_utils.chatmodel import ChatOpenAI  # ./aimakerspace/openai_utils/chatmodel.py\n",
    "\n",
    "chat_openai = ChatOpenAI()\n",
    "user_prompt_template = \"{content}\"\n",
    "user_role_prompt = UserRolePrompt(user_prompt_template)\n",
    "system_prompt_template = (\n",
    "    \"You are an expert in {expertise}, you always answer in a kind way.\"\n",
    ")\n",
    "system_role_prompt = SystemRolePrompt(system_prompt_template)\n",
    "\n",
    "messages = [\n",
    "    system_role_prompt.create_message(expertise=\"Python\"),\n",
    "    user_role_prompt.create_message(\n",
    "        content=\"What is the best way to write a loop?\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "response = chat_openai.run(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dHo7lssNR6yw",
    "outputId": "1d3823fa-bb6b-45f6-ddba-b41686388324"
   },
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2nxxhB2R6yy"
   },
   "source": [
    "## Task 5: Retrieval Augmented Generation\n",
    "\n",
    "> **üì¶ Local Library Components in RAG Pipeline**\n",
    "> \n",
    "> The RAG pipeline below integrates all local `aimakerspace/` components:\n",
    "> - `ChatOpenAI` ‚Äî LLM wrapper from `aimakerspace/openai_utils/chatmodel.py`\n",
    "> - `VectorDatabase` ‚Äî Retriever from `aimakerspace/vectordatabase.py`\n",
    "> - `SystemRolePrompt`, `UserRolePrompt` ‚Äî Message formatters from `aimakerspace/openai_utils/prompts.py`\n",
    "> \n",
    "> **RAG Flow**: Query ‚Üí Vector similarity search (local) ‚Üí Context augmentation ‚Üí LLM generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D1hamzGaR6yy"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RAG PROMPT TEMPLATES\n",
    "# Using SystemRolePrompt and UserRolePrompt from local aimakerspace/openai_utils/prompts.py\n",
    "# =============================================================================\n",
    "\n",
    "RAG_SYSTEM_TEMPLATE = \"\"\"You are a helpful personal wellness assistant that answers health and wellness questions based strictly on provided context.\n",
    "\n",
    "Instructions:\n",
    "- Only answer questions using information from the provided context\n",
    "- If the context doesn't contain relevant information, respond with \"I don't have information about that in my wellness knowledge base\"\n",
    "- Be accurate and cite specific parts of the context when possible\n",
    "- Keep responses {response_style} and {response_length}\n",
    "- Only use the provided context. Do not use external knowledge.\n",
    "- Include a gentle reminder that users should consult healthcare professionals for medical advice when appropriate\n",
    "- Only provide answers when you are confident the context supports your response.\"\"\"\n",
    "\n",
    "RAG_USER_TEMPLATE = \"\"\"Context Information:\n",
    "{context}\n",
    "\n",
    "Number of relevant sources found: {context_count}\n",
    "{similarity_scores}\n",
    "\n",
    "Question: {user_query}\n",
    "\n",
    "Please provide your answer based solely on the context above.\"\"\"\n",
    "\n",
    "rag_system_prompt = SystemRolePrompt(\n",
    "    RAG_SYSTEM_TEMPLATE,\n",
    "    strict=True,\n",
    "    defaults={\n",
    "        \"response_style\": \"concise\",\n",
    "        \"response_length\": \"brief\"\n",
    "    }\n",
    ")\n",
    "\n",
    "rag_user_prompt = UserRolePrompt(\n",
    "    RAG_USER_TEMPLATE,\n",
    "    strict=True,\n",
    "    defaults={\n",
    "        \"context_count\": \"\",\n",
    "        \"similarity_scores\": \"\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalAugmentedQAPipeline:\n",
    "    \"\"\"\n",
    "    RAG Pipeline using local aimakerspace/ library components.\n",
    "    \n",
    "    Dependencies (all from local ./aimakerspace/ directory):\n",
    "        - ChatOpenAI: LLM wrapper from aimakerspace/openai_utils/chatmodel.py\n",
    "        - VectorDatabase: Vector store from aimakerspace/vectordatabase.py\n",
    "        - SystemRolePrompt, UserRolePrompt: From aimakerspace/openai_utils/prompts.py\n",
    "    \n",
    "    The pipeline:\n",
    "        1. Takes a user query\n",
    "        2. Retrieves relevant chunks via VectorDatabase.search_by_text() (cosine similarity)\n",
    "        3. Augments the prompt with retrieved context\n",
    "        4. Generates a grounded response via ChatOpenAI\n",
    "    \"\"\"\n",
    "    def __init__(self, llm: ChatOpenAI, vector_db_retriever: VectorDatabase, \n",
    "                 response_style: str = \"detailed\", include_scores: bool = False) -> None:\n",
    "        self.llm = llm  # From local aimakerspace/openai_utils/chatmodel.py\n",
    "        self.vector_db_retriever = vector_db_retriever  # From local aimakerspace/vectordatabase.py\n",
    "        self.response_style = response_style\n",
    "        self.include_scores = include_scores\n",
    "\n",
    "    def run_pipeline(self, user_query: str, k: int = 4, **system_kwargs) -> dict:\n",
    "        # Retrieve relevant contexts using local VectorDatabase\n",
    "        context_list = self.vector_db_retriever.search_by_text(user_query, k=k)\n",
    "        \n",
    "        context_prompt = \"\"\n",
    "        similarity_scores = []\n",
    "        \n",
    "        for i, (context, score) in enumerate(context_list, 1):\n",
    "            context_prompt += f\"[Source {i}]: {context}\\n\\n\"\n",
    "            similarity_scores.append(f\"Source {i}: {score:.3f}\")\n",
    "        \n",
    "        # Create system message with parameters (using local prompt classes)\n",
    "        system_params = {\n",
    "            \"response_style\": self.response_style,\n",
    "            \"response_length\": system_kwargs.get(\"response_length\", \"detailed\")\n",
    "        }\n",
    "        \n",
    "        formatted_system_prompt = rag_system_prompt.create_message(**system_params)\n",
    "        \n",
    "        user_params = {\n",
    "            \"user_query\": user_query,\n",
    "            \"context\": context_prompt.strip(),\n",
    "            \"context_count\": len(context_list),\n",
    "            \"similarity_scores\": f\"Relevance scores: {', '.join(similarity_scores)}\" if self.include_scores else \"\"\n",
    "        }\n",
    "        \n",
    "        formatted_user_prompt = rag_user_prompt.create_message(**user_params)\n",
    "\n",
    "        return {\n",
    "            \"response\": self.llm.run([formatted_system_prompt, formatted_user_prompt]), \n",
    "            \"context\": context_list,\n",
    "            \"context_count\": len(context_list),\n",
    "            \"similarity_scores\": similarity_scores if self.include_scores else None,\n",
    "            \"prompts_used\": {\n",
    "                \"system\": formatted_system_prompt,\n",
    "                \"user\": formatted_user_prompt\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# INSTANTIATE RAG PIPELINE\n",
    "# Combines local components: ChatOpenAI + VectorDatabase (both from aimakerspace/)\n",
    "# Data source: ./data/HealthWellnessGuide.txt (loaded and chunked earlier)\n",
    "# =============================================================================\n",
    "rag_pipeline = RetrievalAugmentedQAPipeline(\n",
    "    vector_db_retriever=vector_db,  # Local VectorDatabase with embedded wellness docs\n",
    "    llm=chat_openai,  # Local ChatOpenAI wrapper\n",
    "    response_style=\"detailed\",\n",
    "    include_scores=True\n",
    ")\n",
    "\n",
    "result = rag_pipeline.run_pipeline(\n",
    "    \"What are some natural remedies for improving sleep quality?\",\n",
    "    k=3,\n",
    "    response_length=\"comprehensive\", \n",
    "    include_warnings=True,\n",
    "    confidence_required=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Response: {result['response']}\")\n",
    "print(f\"\\nContext Count: {result['context_count']}\")\n",
    "print(f\"Similarity Scores: {result['similarity_scores']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity #1:\n",
    "\n",
    "Enhance your Personal Wellness Assistant in some way! \n",
    "\n",
    "> **üí° Tip: Modify the Local Library**\n",
    "> \n",
    "> Many enhancements require changes to the **local `aimakerspace/` library**:\n",
    "> - Add new distance metrics ‚Üí edit `aimakerspace/vectordatabase.py`\n",
    "> - Support embedding dimension reduction ‚Üí edit `aimakerspace/openai_utils/embedding.py`\n",
    "> - Add PDF support ‚Üí create new loader in `aimakerspace/text_utils.py`\n",
    "> - Add new data sources ‚Üí place files in `data/` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "# Enhancement ideas that use local library/data:\n",
    "# - Modify aimakerspace/vectordatabase.py for new similarity metrics\n",
    "# - Modify aimakerspace/openai_utils/embedding.py for dimension reduction\n",
    "# - Add new loaders to aimakerspace/text_utils.py (e.g., PDFFileLoader)\n",
    "# - Add new data files to data/ directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Tracker - thought experiment\n",
    "\n",
    "Use a DataFrame to capture how parameter adjustments impact RAG results. Key parameters to experiment with:\n",
    "- **k**: Number of retrieved chunks (impacts context breadth vs. relevance)\n",
    "- **response_style**: \"concise\" | \"detailed\" (affects output verbosity)\n",
    "- **response_length**: \"brief\" | \"comprehensive\" (affects output depth)\n",
    "- **chunk_size/overlap**: Requires rebuilding vector_db (see Task 2)\n",
    "\n",
    "> NOTE:  not part of the assignment but may help you understand concepts in you're familiar with similar ML and data science concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Evaluation Datasets\n",
    "\n",
    "Building toward systematic evaluation requires three foundational datasets:\n",
    "\n",
    "| Dataset | Purpose | Analogy |\n",
    "|---------|---------|---------|\n",
    "| **Sources** | Document your chunks | \"What's in the filing cabinet?\" |\n",
    "| **Golden Testset** | Define what good looks like | \"The answer key\" |\n",
    "| **Evaluation Inputs** | Capture what you actually got | \"The student's work\" |\n",
    "\n",
    "These datasets enable **vibe checking** ‚Äî building intuition about retrieval quality before introducing LLM-as-judge metrics in future sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1: RAG Sources\n",
    "\n",
    "Document every chunk with metadata. This helps you understand what's actually in your knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# =============================================================================\n",
    "# DATASET 1: WELLNESS RAG SOURCES\n",
    "# Documents all chunks with metadata\n",
    "# =============================================================================\n",
    "\n",
    "def get_chunk_preview(chunk_text: str, max_len: int = 80) -> str:\n",
    "    \"\"\"Create a readable preview showing control characters for educational purposes.\n",
    "    \n",
    "    Shows \\\\n literally so students can see where newlines occur in the text.\n",
    "    This helps understand chunking artifacts (e.g., fragments like ' Relief\\\\n').\n",
    "    \n",
    "    Note: \\\\n is a single character (ASCII 10), displayed as two chars for visibility.\n",
    "    \"\"\"\n",
    "    # Take first max_len chars and replace newlines with visible \\n\n",
    "    preview = chunk_text[:max_len].replace('\\n', '\\\\n').replace('\\r', '\\\\r')\n",
    "    return preview + \"...\" if len(chunk_text) > max_len else preview\n",
    "\n",
    "# Build the sources dataset\n",
    "wellness_rag_sources = pd.DataFrame({\n",
    "    \"chunk_id\": range(len(split_documents)),\n",
    "    \"chunk_content\": split_documents,\n",
    "    \"preview\": [get_chunk_preview(chunk) for chunk in split_documents],\n",
    "    \"char_count\": [len(chunk) for chunk in split_documents],\n",
    "    \"word_count\": [len(chunk.split()) for chunk in split_documents],\n",
    "    # Metadata about chunking settings - dynamically retrieved from splitter instance\n",
    "    \"chunk_size\": text_splitter.chunk_size,\n",
    "    \"chunk_overlap\": text_splitter.chunk_overlap,\n",
    "    \"source_file\": \"data/HealthWellnessGuide.txt\",\n",
    "})\n",
    "\n",
    "print(f\"üìö RAG Sources Dataset: {len(wellness_rag_sources)} chunks\\n\")\n",
    "display(wellness_rag_sources[[\"chunk_id\", \"preview\", \"char_count\", \"word_count\", \"chunk_size\", \"chunk_overlap\", \"source_file\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2: Golden Testset\n",
    "\n",
    "Define \"what good looks like\" ‚Äî curated question-answer pairs. This is your answer key for vibe checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATASET 2: WELLNESS GOLDEN TESTSET\n",
    "# Curated Q&A pairs with expected retrievals - your \"answer key\"\n",
    "# =============================================================================\n",
    "\n",
    "# Define the golden testset\n",
    "wellness_golden_testset_raw = [\n",
    "    {\n",
    "        \"question_id\": 1,\n",
    "        \"question\": \"What exercises help with lower back pain?\",\n",
    "        \"reference_answer\": \"Recommended exercises for lower back pain include Cat-Cow Stretch, Bird Dog, Partial Crunches, Knee-to-Chest Stretch, and Pelvic Tilts.\",\n",
    "        \"difficulty\": \"simple\",\n",
    "    },\n",
    "    {\n",
    "        \"question_id\": 2,\n",
    "        \"question\": \"What are natural remedies for improving sleep quality?\",\n",
    "        \"reference_answer\": \"Natural sleep remedies include herbal teas (chamomile, valerian root), magnesium supplements, meditation, relaxation techniques, and good sleep hygiene practices.\",\n",
    "        \"difficulty\": \"simple\",\n",
    "    },\n",
    "    {\n",
    "        \"question_id\": 3,\n",
    "        \"question\": \"How can I relieve neck and shoulder tension?\",\n",
    "        \"reference_answer\": \"Exercises for neck and shoulder tension include Neck Rolls, Shoulder Shrugs, Chest Opener stretches, and Chin Tucks.\",\n",
    "        \"difficulty\": \"simple\",\n",
    "    },\n",
    "    {\n",
    "        \"question_id\": 4,\n",
    "        \"question\": \"How can I manage stress naturally?\",\n",
    "        \"reference_answer\": \"Natural stress management includes deep breathing exercises, meditation, regular physical activity, adequate sleep, and relaxation techniques.\",\n",
    "        \"difficulty\": \"simple\",\n",
    "    },\n",
    "    {\n",
    "        \"question_id\": 5,\n",
    "        \"question\": \"What should I eat for better energy and nutrition?\",\n",
    "        \"reference_answer\": \"For better energy, eat balanced meals with lean proteins, complex carbohydrates, healthy fats, and plenty of fruits and vegetables rich in vitamins and minerals.\",\n",
    "        \"difficulty\": \"simple\",\n",
    "    },\n",
    "    {\n",
    "        \"question_id\": 6,\n",
    "        \"question\": \"How much water should I drink daily?\",\n",
    "        \"reference_answer\": \"General hydration guidelines recommend drinking adequate water throughout the day, typically 8 glasses or adjusting based on activity level and climate.\",\n",
    "        \"difficulty\": \"simple\",\n",
    "    },\n",
    "    {\n",
    "        \"question_id\": 7,\n",
    "        \"question\": \"How do exercise and sleep work together for overall wellness?\",\n",
    "        \"reference_answer\": \"Exercise improves sleep quality by reducing stress and promoting physical tiredness, while adequate sleep supports muscle recovery and provides energy for physical activity.\",\n",
    "        \"difficulty\": \"multi-hop\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Build DataFrame\n",
    "wellness_golden_testset = pd.DataFrame(wellness_golden_testset_raw)\n",
    "\n",
    "print(f\"üéØ Golden Testset: {len(wellness_golden_testset)} questions\\n\")\n",
    "display(wellness_golden_testset[[\"question_id\", \"question\", \"difficulty\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 3: Evaluation Inputs\n",
    "\n",
    "Capture what your retriever actually returns for each golden testset question. Compare retrieved vs. expected to compute simple metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATASET 3: WELLNESS EVALUATION INPUTS\n",
    "# Simple capture of RAG pipeline inputs and outputs (like GDELT dataset)\n",
    "# =============================================================================\n",
    "\n",
    "evaluation_inputs = []\n",
    "\n",
    "for _, test_row in wellness_golden_testset.iterrows():\n",
    "    # Run the RAG pipeline\n",
    "    result = rag_pipeline.run_pipeline(test_row[\"question\"], k=3)\n",
    "    \n",
    "    # Capture simple inputs/outputs\n",
    "    evaluation_inputs.append({\n",
    "        \"user_input\": test_row[\"question\"],\n",
    "        \"retrieved_contexts\": [ctx for ctx, score in result[\"context\"]],\n",
    "        \"response\": result[\"response\"],\n",
    "        \"reference\": test_row[\"reference_answer\"],\n",
    "    })\n",
    "\n",
    "wellness_evaluation_inputs = pd.DataFrame(evaluation_inputs)\n",
    "\n",
    "print(f\"üìä Evaluation Inputs: {len(wellness_evaluation_inputs)} rows\\n\")\n",
    "display(wellness_evaluation_inputs[[\"user_input\", \"response\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View full dataset structure\n",
    "print(\"üìã Full Dataset Columns:\\n\")\n",
    "print(wellness_evaluation_inputs.columns.tolist())\n",
    "\n",
    "print(\"\\nüìÑ Sample row (first question):\\n\")\n",
    "print(f\"user_input: {wellness_evaluation_inputs.iloc[0]['user_input']}\")\n",
    "print(f\"\\nretrieved_contexts: {len(wellness_evaluation_inputs.iloc[0]['retrieved_contexts'])} chunks\")\n",
    "print(f\"\\nresponse (first 200 chars): {wellness_evaluation_inputs.iloc[0]['response'][:200]}...\")\n",
    "print(f\"\\nreference: {wellness_evaluation_inputs.iloc[0]['reference']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vibe Check: Compare Response to Reference\n",
    "\n",
    "Use this to manually review if the LLM response captures the key information from the reference answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VIBE CHECK: Side-by-side comparison of response vs reference\n",
    "# =============================================================================\n",
    "\n",
    "for idx, row in wellness_evaluation_inputs.iterrows():\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Q{idx+1}: {row['user_input']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\nüìù RESPONSE (from LLM):\\n{row['response'][:400]}...\")\n",
    "    print(f\"\\n‚úì REFERENCE (expected):\\n{row['reference']}\")\n",
    "    print(f\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT DATASETS (Optional)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üì¶ Dataset Summary:\\n\")\n",
    "print(f\"  wellness_rag_sources:        {wellness_rag_sources.shape[0]} rows √ó {wellness_rag_sources.shape[1]} cols\")\n",
    "print(f\"  wellness_golden_testset:     {wellness_golden_testset.shape[0]} rows √ó {wellness_golden_testset.shape[1]} cols\")\n",
    "print(f\"  wellness_evaluation_inputs:  {wellness_evaluation_inputs.shape[0]} rows √ó {wellness_evaluation_inputs.shape[1]} cols\")\n",
    "\n",
    "print(\"\\nüìã Evaluation Inputs Schema (matches GDELT pattern):\")\n",
    "print(\"  ‚Ä¢ user_input:          The question\")\n",
    "print(\"  ‚Ä¢ retrieved_contexts:  List of retrieved chunks\")\n",
    "print(\"  ‚Ä¢ response:            LLM's generated answer\")\n",
    "print(\"  ‚Ä¢ reference:           Expected answer from golden testset\")\n",
    "\n",
    "# Uncomment to export\n",
    "# wellness_rag_sources.to_csv(\"wellness_rag_sources.csv\", index=False)\n",
    "# wellness_golden_testset.to_csv(\"wellness_golden_testset.csv\", index=False)\n",
    "# wellness_evaluation_inputs.to_csv(\"wellness_evaluation_inputs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "02-embeddings-and-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
